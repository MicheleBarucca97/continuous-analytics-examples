{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting confluent-kafka==1.4.2\n",
      "  Downloading confluent_kafka-1.4.2-cp38-cp38-manylinux1_x86_64.whl (8.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.1 MB 31.8 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: confluent-kafka\n",
      "Successfully installed confluent-kafka-1.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install confluent-kafka==1.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: confluent-kafka[avro]==1.4.2 in /opt/conda/lib/python3.8/site-packages (1.4.2)\n",
      "Collecting fastavro>=0.23.0; extra == \"avro\"\n",
      "  Downloading fastavro-1.1.0-cp38-cp38-manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 22.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting avro-python3==1.9.2.1; python_version > \"3.0\" and extra == \"avro\"\n",
      "  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n",
      "Requirement already satisfied: requests; extra == \"avro\" in /opt/conda/lib/python3.8/site-packages (from confluent-kafka[avro]==1.4.2) (2.24.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests; extra == \"avro\"->confluent-kafka[avro]==1.4.2) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests; extra == \"avro\"->confluent-kafka[avro]==1.4.2) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests; extra == \"avro\"->confluent-kafka[avro]==1.4.2) (1.25.11)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests; extra == \"avro\"->confluent-kafka[avro]==1.4.2) (2020.6.20)\n",
      "Building wheels for collected packages: avro-python3\n",
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43513 sha256=41e6dbd6d1d7f7bef8755355792691cca372629fc2994f746bd8710c0d6d58b0\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/a5/f2/87/b7c4b9d5915716d94e8bf2e2f3bfbbd73bb5fe2a98677a59cb\n",
      "Successfully built avro-python3\n",
      "Installing collected packages: fastavro, avro-python3\n",
      "Successfully installed avro-python3-1.9.2.1 fastavro-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install confluent-kafka[avro]==1.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka.admin import AdminClient, NewTopic, NewPartitions\n",
    "from confluent_kafka import KafkaException\n",
    "import sys\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_server = \"kafka:9092\" # Brokers act as cluster entripoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {'bootstrap.servers': bootstrap_server}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AdminClient(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9 topics:\n",
      "  \"ratings\" with 1 partition(s)\n",
      "  \"confluent_rmoff_01ksql_processing_log\" with 1 partition(s)\n"
     ]
    }
   ],
   "source": [
    "md = a.list_topics(timeout=10)\n",
    "print(\" {} topics:\".format(len(md.topics)))\n",
    "for t in iter(md.topics.values()):\n",
    "    if t.error is not None:\n",
    "        errstr = \": {}\".format(t.error)\n",
    "    else:\n",
    "        errstr = \"\"\n",
    "    if not (str(t)).startswith(\"_\"):\n",
    "        print(\"  \\\"{}\\\" with {} partition(s){}\".format(t, len(t.partitions), errstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = a.create_topics([NewTopic(\"test1p\", num_partitions=1, replication_factor=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to create topic test1p: KafkaError{code=_TIMED_OUT,val=-185,str=\"Failed while waiting for controller: Local: Timed out\"}\n"
     ]
    }
   ],
   "source": [
    "for topic, f in fs.items():\n",
    "    try:\n",
    "        f.result()  # The result itself is None\n",
    "        print(\"Topic {} created\".format(topic))\n",
    "    except Exception as e:\n",
    "        print(\"Failed to create topic {}: {}\".format(topic, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producer and Consumer API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the class, we start producing and consuming from a topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to Topic \"test1p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Producer\n",
    "import sys\n",
    "conf = {'bootstrap.servers': brokers}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Producer(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Producer API requires a call back function to control the message delivery (Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delivery_callback(err, msg):\n",
    "        if err:\n",
    "            sys.stderr.write('%% Message failed delivery: %s\\n' % err)\n",
    "        else:\n",
    "            sys.stderr.write('%% Message delivered to %s [%d] @ %d\\n' %\n",
    "                             (msg.topic(), msg.partition(), msg.offset()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's send some messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1,10):\n",
    "    try:\n",
    "        # Produce line (without newline)\n",
    "        print(n)\n",
    "        p.produce(topic_names[0], str(n), callback=delivery_callback)\n",
    "        p.flush(0)\n",
    "    except BufferError:\n",
    "        sys.stderr.write('%% Local producer queue is full (%d messages awaiting delivery): try again\\n' % len(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensure nothing is in the buffered by the producer.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.poll(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from Topic \"test1p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import Consumer, KafkaException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    'bootstrap.servers': brokers, \n",
    "    'group.id': str(uuid4()), \n",
    "    'session.timeout.ms': 6000,\n",
    "    'auto.offset.reset': 'earliest'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Consumer(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.subscribe([topic_names[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read messages from Kafka, print to stdout\n",
    "try:\n",
    "    while True: #Consumer run forever\n",
    "        msg = c.poll(timeout=1.0)\n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            raise KafkaException(msg.error())\n",
    "        else:\n",
    "            # Proper message\n",
    "            sys.stderr.write('%% %s [%d] at offset %d with key %s:\\n' %\n",
    "             (msg.topic(), msg.partition(), msg.offset(), str(msg.key())))\n",
    "            print(msg.value())\n",
    "except KeyboardInterrupt:\n",
    "    sys.stderr.write('%% Aborted by user\\n')\n",
    "finally:\n",
    "    # Close down consumer to commit final offsets.\n",
    "    c.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write to Topic \"test2p\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is important about \"test2p\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {'bootstrap.servers': brokers}\n",
    "p = Producer(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(1,10):\n",
    "    try:\n",
    "        # Produce line (without newline)\n",
    "        print(n)\n",
    "        p.produce(topic_names[1], str(n), callback=delivery_callback)\n",
    "        p.poll(0)\n",
    "        p.flush()\n",
    "    except BufferError:\n",
    "        sys.stderr.write('%% Local producer queue is full (%d messages awaiting delivery): try again\\n' % len(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from Topic \"test2p\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {\n",
    "    'bootstrap.servers': brokers, \n",
    "    'group.id': str(uuid4()), \n",
    "    'session.timeout.ms': 6000,\n",
    "    'auto.offset.reset': 'earliest'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = Consumer(conf)\n",
    "c.subscribe([topic_names[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read messages from Kafka, print to stdout\n",
    "try:\n",
    "    while True:\n",
    "        msg = c.poll(timeout=1.0)\n",
    "        if msg is None:\n",
    "            continue\n",
    "        if msg.error():\n",
    "            raise KafkaException(msg.error())\n",
    "        else:\n",
    "            # Proper message\n",
    "            print(\"{} [{}] at offset {} with key  {}:  {}\".format(msg.topic(), msg.partition(), msg.offset(), str(msg.key()), str(msg.value())))\n",
    "except KeyboardInterrupt:\n",
    "    sys.stderr.write('%% Aborted by user\\n')\n",
    "finally:\n",
    "    # Close down consumer to commit final offsets.\n",
    "    c.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What do you notice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://github.com/DataSystemsGroupUT/dataeng/raw/dataeng/attachments/order.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
