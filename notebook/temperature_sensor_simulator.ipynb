{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install confluent-kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install confluent-kafka[avro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka.admin import AdminClient, NewTopic, NewPartitions\n",
    "from confluent_kafka import KafkaException\n",
    "import sys\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_server = \"kafka:9092\" # Brokers act as cluster entripoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {'bootstrap.servers': bootstrap_server}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AdminClient(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = a.list_topics(timeout=10)\n",
    "print(\" {} topics:\".format(len(md.topics)))\n",
    "for t in iter(md.topics.values()):\n",
    "    if t.error is not None:\n",
    "        errstr = \": {}\".format(t.error)\n",
    "    else:\n",
    "        errstr = \"\"\n",
    "    ##if not (str(t)).startswith(\"_\"):\n",
    "    print(\"  \\\"{}\\\" with {} partition(s){}\".format(t, len(t.partitions), errstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fs = a.create_topics([NewTopic(\"test1p\", num_partitions=1, replication_factor=1)])\n",
    "\n",
    "#for topic, f in fs.items():\n",
    "#    try:\n",
    "#        f.result()  # The result itself is None\n",
    "#        print(\"Topic {} created\".format(topic))\n",
    "#    except Exception as e:\n",
    "#        print(\"Failed to create topic {}: {}\".format(topic, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the value schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_schema_str = \"\"\"\n",
    "{\n",
    "  \"namespace\": \"continuous.analytics\",\n",
    "  \"type\": \"record\",\n",
    "  \"name\": \"TemperatureSensorEvent\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"sensor\",\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"temperature\",\n",
    "      \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ts\",\n",
    "      \"type\": \"long\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import SerializingProducer\n",
    "from confluent_kafka.serialization import *\n",
    "from confluent_kafka.schema_registry import SchemaRegistryClient\n",
    "from confluent_kafka.schema_registry.avro import AvroSerializer\n",
    "import time\n",
    "\n",
    "topic = \"TemperatureSensorEvent\"\n",
    "schema_registry_url = \"http://schema-registry:8081\"\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(\"Failed to deliver message: {}\".format(err))\n",
    "    else:\n",
    "        print(\"Produced record to topic {} partition [{}] @ offset {}\"\n",
    "              .format(msg.topic(), msg.partition(), msg.offset()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_registry_conf = {'url': schema_registry_url}\n",
    "schema_registry_client = SchemaRegistryClient(schema_registry_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avro_serializer = AvroSerializer(value_schema_str, schema_registry_client)\n",
    "\n",
    "producer_conf = {\n",
    "        'bootstrap.servers': bootstrap_server,\n",
    "        'key.serializer': StringSerializer('utf_8'),\n",
    "        'value.serializer': avro_serializer\n",
    "}\n",
    "\n",
    "producer = SerializingProducer(producer_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import gauss\n",
    "\n",
    "while True:\n",
    "    key = \"S1\"\n",
    "    value = {\"sensor\": \"S1\",\"temperature\": gauss(50, 1.0),\"ts\":int(time.time()*1000.0)}\n",
    "    producer.produce(topic=topic, value=value, key=key, on_delivery=delivery_report)\n",
    "    print(value)\n",
    "    producer.poll(1)\n",
    "    time.sleep(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    key = \"S1\"\n",
    "    value = {\"sensor\": \"S1\",\"temperature\": gauss(50, 1.0),\"ts\":int(time.time()*1000.0)}\n",
    "    producer.produce(topic=topic, value=value, key=key, on_delivery=delivery_report)\n",
    "    print(value)\n",
    "    producer.poll(1)\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
