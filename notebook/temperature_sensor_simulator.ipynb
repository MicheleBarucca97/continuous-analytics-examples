{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: confluent-kafka in /opt/conda/lib/python3.8/site-packages (1.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install confluent-kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: confluent-kafka[avro] in /opt/conda/lib/python3.8/site-packages (1.5.0)\n",
      "Requirement already satisfied: fastavro>=0.23.0; extra == \"avro\" in /opt/conda/lib/python3.8/site-packages (from confluent-kafka[avro]) (1.1.1)\n",
      "Requirement already satisfied: avro-python3==1.10.0; python_version > \"3.0\" and extra == \"avro\" in /opt/conda/lib/python3.8/site-packages (from confluent-kafka[avro]) (1.10.0)\n",
      "Requirement already satisfied: requests; extra == \"avro\" in /opt/conda/lib/python3.8/site-packages (from confluent-kafka[avro]) (2.24.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests; extra == \"avro\"->confluent-kafka[avro]) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests; extra == \"avro\"->confluent-kafka[avro]) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests; extra == \"avro\"->confluent-kafka[avro]) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests; extra == \"avro\"->confluent-kafka[avro]) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install confluent-kafka[avro]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka.admin import AdminClient, NewTopic, NewPartitions\n",
    "from confluent_kafka import KafkaException\n",
    "import sys\n",
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_server = \"kafka:9092\" # Brokers act as cluster entripoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {'bootstrap.servers': bootstrap_server}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = AdminClient(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 11 topics:\n",
      "  \"__transaction_state\" with 50 partition(s)\n",
      "  \"_kafka-connect-01-offsets\" with 25 partition(s)\n",
      "  \"_schemas\" with 1 partition(s)\n",
      "  \"_confluent-ksql-confluent_rmoff_01_command_topic\" with 1 partition(s)\n",
      "  \"SmokeSensorEvent\" with 1 partition(s)\n",
      "  \"iot-oven\" with 1 partition(s)\n",
      "  \"_kafka-connect-01-configs\" with 1 partition(s)\n",
      "  \"__consumer_offsets\" with 50 partition(s)\n",
      "  \"_kafka-connect-01-status\" with 5 partition(s)\n",
      "  \"ratings\" with 1 partition(s)\n",
      "  \"confluent_rmoff_01ksql_processing_log\" with 1 partition(s)\n"
     ]
    }
   ],
   "source": [
    "md = a.list_topics(timeout=10)\n",
    "print(\" {} topics:\".format(len(md.topics)))\n",
    "for t in iter(md.topics.values()):\n",
    "    if t.error is not None:\n",
    "        errstr = \": {}\".format(t.error)\n",
    "    else:\n",
    "        errstr = \"\"\n",
    "    ##if not (str(t)).startswith(\"_\"):\n",
    "    print(\"  \\\"{}\\\" with {} partition(s){}\".format(t, len(t.partitions), errstr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fs = a.create_topics([NewTopic(\"test1p\", num_partitions=1, replication_factor=1)])\n",
    "\n",
    "#for topic, f in fs.items():\n",
    "#    try:\n",
    "#        f.result()  # The result itself is None\n",
    "#        print(\"Topic {} created\".format(topic))\n",
    "#    except Exception as e:\n",
    "#        print(\"Failed to create topic {}: {}\".format(topic, e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the value schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_schema_str = \"\"\"\n",
    "{\n",
    "  \"namespace\": \"hoven\",\n",
    "  \"type\": \"record\",\n",
    "  \"name\": \"TemperatureSensorEvent\",\n",
    "  \"fields\": [\n",
    "    {\n",
    "      \"name\": \"sensor\",\n",
    "      \"type\": \"string\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"temperature\",\n",
    "      \"type\": \"float\"\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"ts\",\n",
    "      \"type\": \"long\"\n",
    "    }\n",
    "  ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from confluent_kafka import SerializingProducer\n",
    "from confluent_kafka.serialization import *\n",
    "from confluent_kafka.schema_registry import SchemaRegistryClient\n",
    "from confluent_kafka.schema_registry.avro import AvroSerializer\n",
    "import time\n",
    "\n",
    "topic = \"TemperatureSensorEvent\"\n",
    "schema_registry_url = \"http://schema-registry:8081\"\n",
    "\n",
    "def delivery_report(err, msg):\n",
    "    if err is not None:\n",
    "        print(\"Failed to deliver message: {}\".format(err))\n",
    "    else:\n",
    "        print(\"Produced record to topic {} partition [{}] @ offset {}\"\n",
    "              .format(msg.topic(), msg.partition(), msg.offset()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_registry_conf = {'url': schema_registry_url}\n",
    "schema_registry_client = SchemaRegistryClient(schema_registry_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "avro_serializer = AvroSerializer(value_schema_str, schema_registry_client)\n",
    "\n",
    "producer_conf = {\n",
    "        'bootstrap.servers': bootstrap_server,\n",
    "        'key.serializer': StringSerializer('utf_8'),\n",
    "        'value.serializer': avro_serializer\n",
    "}\n",
    "\n",
    "producer = SerializingProducer(producer_conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sensor': 'S1', 'temperature': 28.2353344077577, 'ts': 1605589368191}\n",
      "{'sensor': 'S1', 'temperature': 18.029587531471737, 'ts': 1605589379213}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8b364e8006c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mproducer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from random import gauss\n",
    "i = 0;\n",
    "\n",
    "while True:\n",
    "    i += 1\n",
    "    key = \"S1\"\n",
    "    value = {\"sensor\": \"S1\",\"temperature\": gauss(20, 5.0),\"ts\":int(time.time()*1000.0)}\n",
    "    producer.produce(topic=topic, value=value, key=key, on_delivery=delivery_report)\n",
    "    print(value)\n",
    "    producer.poll(1)\n",
    "    time.sleep(10)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
