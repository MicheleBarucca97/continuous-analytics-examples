{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://5319dee950e5:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f5a7890f520>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "import io\n",
    "from pyspark.sql.functions import *\n",
    "import time\n",
    "import json\n",
    "import struct\n",
    "import requests \n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1,org.apache.spark:spark-streaming-kafka-0-10_2.11:2.4.5,org.apache.kafka:kafka-clients:2.6.0 pyspark-shell'\n",
    "                                    \n",
    "spark = (SparkSession.builder \n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"test\")\n",
    "    .getOrCreate()\n",
    "        )\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke_topic = 'SmokeSensorEvent'\n",
    "temperature_topic = 'TemperatureSensorEvent'\n",
    "servers = \"kafka:9092\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke_df = (spark\n",
    "  .read\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", servers)\n",
    "  .option(\"subscribe\", smoke_topic)\n",
    "  .option(\"startingOffsets\", \"earliest\")\n",
    "  .option(\"endingOffsets\", \"latest\")\n",
    "  .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: binary (nullable = true)\n",
      " |-- value: binary (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      " |-- partition: integer (nullable = true)\n",
      " |-- offset: long (nullable = true)\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- timestampType: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smoke_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------+---------+------+--------------------+-------------+\n",
      "|    key|               value|           topic|partition|offset|           timestamp|timestampType|\n",
      "+-------+--------------------+----------------+---------+------+--------------------+-------------+\n",
      "|[53 31]|[7B 22 73 65 6E 7...|SmokeSensorEvent|        0|     0|2020-11-24 14:14:...|            0|\n",
      "|[53 31]|[7B 22 73 65 6E 7...|SmokeSensorEvent|        0|     1|2020-11-24 14:14:...|            0|\n",
      "|[53 31]|[7B 22 73 65 6E 7...|SmokeSensorEvent|        0|     2|2020-11-24 14:14:...|            0|\n",
      "|[53 31]|[7B 22 73 65 6E 7...|SmokeSensorEvent|        0|     3|2020-11-24 14:14:...|            0|\n",
      "|[53 31]|[7B 22 73 65 6E 7...|SmokeSensorEvent|        0|     4|2020-11-24 14:14:...|            0|\n",
      "+-------+--------------------+----------------+---------+------+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "smoke_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------------------------------------------------+\n",
      "|key|value                                             |\n",
      "+---+--------------------------------------------------+\n",
      "|S1 |{\"sensor\": \"S1\", \"smoke\": false, \"ts\": 1606227254}|\n",
      "|S1 |{\"sensor\": \"S1\", \"smoke\": false, \"ts\": 1606227265}|\n",
      "|S1 |{\"sensor\": \"S1\", \"smoke\": false, \"ts\": 1606227275}|\n",
      "|S1 |{\"sensor\": \"S1\", \"smoke\": false, \"ts\": 1606227285}|\n",
      "|S1 |{\"sensor\": \"S1\", \"smoke\": false, \"ts\": 1606227295}|\n",
      "+---+--------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stringified_smoke_df = smoke_df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "stringified_smoke_df.show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "smoke_schema = StructType([\n",
    "    StructField(\"sensor\", StringType(), True),\n",
    "    StructField(\"smoke\", BooleanType(), True),\n",
    "    StructField(\"ts\", TimestampType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_smoke_df = stringified_smoke_df.select(col(\"key\").cast(\"string\"),from_json(col(\"value\"), smoke_schema).alias(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- key: string (nullable = true)\n",
      " |-- value: struct (nullable = true)\n",
      " |    |-- sensor: string (nullable = true)\n",
      " |    |-- smoke: boolean (nullable = true)\n",
      " |    |-- ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoded_smoke_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------------------+\n",
      "|sensor|smoke|                 ts|\n",
      "+------+-----+-------------------+\n",
      "|    S1|false|2020-11-24 14:14:14|\n",
      "|    S1|false|2020-11-24 14:14:25|\n",
      "|    S1|false|2020-11-24 14:14:35|\n",
      "|    S1|false|2020-11-24 14:14:45|\n",
      "|    S1|false|2020-11-24 14:14:55|\n",
      "+------+-----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "decoded_smoke_df.select(\"value.*\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_smoke_df = (spark\n",
    "  .readStream\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", servers)\n",
    "  .option(\"startingOffsets\", \"earliest\")\n",
    "  .option(\"subscribe\", smoke_topic)\n",
    "  .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_streaming_smoke_df=(streaming_smoke_df\n",
    "                      .select(from_json(col(\"value\").cast(\"string\"), schema).alias(\"value\"))\n",
    "                      .select(\"value.*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke_query = (decoded_streaming_smoke_df\n",
    "    .writeStream\n",
    "    .format(\"memory\")\n",
    "    .queryName(\"SmokeSensorEvent\")\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------------------+\n",
      "|sensor|smoke|                 ts|\n",
      "+------+-----+-------------------+\n",
      "|    S1|false|2020-11-24 14:14:14|\n",
      "|    S1|false|2020-11-24 14:14:25|\n",
      "|    S1|false|2020-11-24 14:14:35|\n",
      "|    S1|false|2020-11-24 14:14:45|\n",
      "|    S1|false|2020-11-24 14:14:55|\n",
      "+------+-----+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM SmokeSensorEvent LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperarture_schema = StructType([\n",
    "    StructField(\"sensor\", StringType(), True),\n",
    "    StructField(\"temperature\", DoubleType(), True),\n",
    "    StructField(\"ts\", TimestampType(), True)])\n",
    "\n",
    "streaming_temperature_df = (spark\n",
    "  .readStream\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", servers)\n",
    "  .option(\"startingOffsets\", \"earliest\")\n",
    "  .option(\"subscribe\", temperature_topic)\n",
    "  .load())\n",
    "\n",
    "decoded_streaming_temperature_df = (streaming_temperature_df\n",
    "                      .select(from_json(col(\"value\").cast(\"string\"), temperarture_schema).alias(\"value\"))\n",
    "                      .select(\"value.*\"))\n",
    "\n",
    "temperature_query = (decoded_streaming_temperature_df\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"TemperatureSensorEvent\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- sensor: string (nullable = true)\n",
      " |-- temperature: boolean (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "streaming_temperature_df.select(from_json(col(\"value\").cast(\"string\"), temperarture_schema).alias(\"value\")).select(\"value.*\").printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q0 - Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+-------------------+\n",
      "|sensor|       temperature|                 ts|\n",
      "+------+------------------+-------------------+\n",
      "|    S1|20.763870006867744|2020-11-24 14:22:07|\n",
      "|    S1| 21.16533247355798|2020-11-24 14:22:18|\n",
      "|    S1|20.943058476233357|2020-11-24 14:23:08|\n",
      "|    S1| 21.67293464162423|2020-11-24 14:23:28|\n",
      "|    S1| 20.61440334054661|2020-11-24 14:23:38|\n",
      "+------+------------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM TemperatureSensorEvent WHERE temperature > 20\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 - Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------------------+\n",
      "|sensor|smoke|                 ts|\n",
      "+------+-----+-------------------+\n",
      "|    S1|false|2020-11-24 14:14:14|\n",
      "|    S1|false|2020-11-24 14:14:25|\n",
      "|    S1|false|2020-11-24 14:14:35|\n",
      "|    S1|false|2020-11-24 14:14:45|\n",
      "|    S1|false|2020-11-24 14:14:55|\n",
      "+------+-----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM SmokeSensorEvent\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------------------+\n",
      "|sensor|smoke|                 ts|\n",
      "+------+-----+-------------------+\n",
      "|    S1| true|2020-11-24 14:37:05|\n",
      "|    S1| true|2020-11-24 14:37:15|\n",
      "|    S1| true|2020-11-24 14:37:25|\n",
      "|    S1| true|2020-11-24 14:37:35|\n",
      "|    S1| true|2020-11-24 14:37:45|\n",
      "+------+-----+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM SmokeSensorEvent WHERE smoke\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 - Avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|SENSOR|  avg(temperature)|\n",
      "+------+------------------+\n",
      "|    S1|25.755518607259987|\n",
      "+------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "SELECT SENSOR, AVG(temperature) \n",
    "FROM TemperatureSensorEvent\n",
    "GROUP BY SENSOR\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 - Logical Sliding Window\n",
    "\n",
    "**Not supported**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 - Logical Tumbling Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "LTW_temperature_query = (decoded_streaming_temperature_df\n",
    "                         .withWatermark(\"TS\", \"10 minutes\")\n",
    "                         .groupBy(window(\"TS\", \"1 minutes\"),\"SENSOR\")\n",
    "                         .avg(\"TEMPERATURE\")\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"results\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+------+------------------+\n",
      "|window                                    |SENSOR|avg(TEMPERATURE)  |\n",
      "+------------------------------------------+------+------------------+\n",
      "|[2020-11-24 14:40:00, 2020-11-24 14:41:00]|S1    |54.78537965704618 |\n",
      "|[2020-11-24 14:29:00, 2020-11-24 14:30:00]|S1    |19.656529885025204|\n",
      "|[2020-11-24 14:26:00, 2020-11-24 14:27:00]|S1    |20.253691894608895|\n",
      "|[2020-11-24 14:34:00, 2020-11-24 14:35:00]|S1    |20.07524626663701 |\n",
      "|[2020-11-24 14:36:00, 2020-11-24 14:37:00]|S1    |19.384828838569067|\n",
      "+------------------------------------------+------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM results ORDER BY window\").show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "LTW_temperature_query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 - Physical Sliding Window\n",
    "\n",
    "**Not supported**\n",
    "\n",
    "## Q6 - Physical Tumbling Window\n",
    "\n",
    "**Not supported**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7 - Logical Hopping Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "LHW_temperature_query = (decoded_streaming_temperature_df\n",
    "                         .withWatermark(\"TS\", \"10 minutes\")\n",
    "                         .groupBy(window(\"TS\", \"1 minutes\", \"5 seconds\"),\"SENSOR\")\n",
    "                         .avg(\"TEMPERATURE\")\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"results\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+------+------------------+\n",
      "|window                                    |SENSOR|avg(TEMPERATURE)  |\n",
      "+------------------------------------------+------+------------------+\n",
      "|[2020-11-24 14:21:10, 2020-11-24 14:22:10]|S1    |20.763870006867744|\n",
      "|[2020-11-24 14:21:15, 2020-11-24 14:22:15]|S1    |20.763870006867744|\n",
      "|[2020-11-24 14:21:20, 2020-11-24 14:22:20]|S1    |20.964601240212865|\n",
      "|[2020-11-24 14:21:25, 2020-11-24 14:22:25]|S1    |20.964601240212865|\n",
      "|[2020-11-24 14:21:30, 2020-11-24 14:22:30]|S1    |20.50070180868975 |\n",
      "+------------------------------------------+------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM results ORDER BY window\").show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "note the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "LHW_temperature_query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8 - Stream-to-Stream Join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: this stream-to-stream join is equivalent to the EPL pattern `every a = SmokeSensorEvent(smoke=true) -> every TemperatureSensorEvent(temperature > 50, sensor=a.sensor) where timer:within(1 min)`. Do not expect the same performances! It is evaluated differently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply watermarks on event-time columns and other filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_minute_smoke_events = (decoded_streaming_smoke_df\n",
    "                .withWatermark(\"ts\", \"1 minute\")\n",
    "                .filter(col(\"smoke\") == True)\n",
    "               )\n",
    "\n",
    "last_minute_high_temperature_events = (decoded_streaming_temperature_df\n",
    "                .withWatermark(\"ts\", \"1 minute\")\n",
    "                .filter(col(\"temperature\") > 50)\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join with event-time constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_df = (last_minute_smoke_events.join(\n",
    "  last_minute_high_temperature_events,\n",
    "    (last_minute_smoke_events.sensor == last_minute_high_temperature_events.sensor) &\n",
    "    (last_minute_smoke_events.ts < last_minute_high_temperature_events.ts))\n",
    "           .select(last_minute_smoke_events.sensor,\n",
    "                   last_minute_smoke_events.smoke,\n",
    "                   last_minute_high_temperature_events.temperature,\n",
    "                   last_minute_smoke_events.ts\n",
    "                  ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_to_s_join_query = (join_df\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"results\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------------------+------+----------------+-------------------+\n",
      "|sensor|smoke|ts                 |sensor|temperature     |ts                 |\n",
      "+------+-----+-------------------+------+----------------+-------------------+\n",
      "|S1    |true |2020-11-24 14:37:05|S1    |54.2981082858924|2020-11-24 14:38:18|\n",
      "|S1    |true |2020-11-24 14:37:15|S1    |54.2981082858924|2020-11-24 14:38:18|\n",
      "|S1    |true |2020-11-24 14:37:25|S1    |54.2981082858924|2020-11-24 14:38:18|\n",
      "|S1    |true |2020-11-24 14:37:35|S1    |54.2981082858924|2020-11-24 14:38:18|\n",
      "|S1    |true |2020-11-24 14:37:45|S1    |54.2981082858924|2020-11-24 14:38:18|\n",
      "+------+-----+-------------------+------+----------------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM results\").show(5,False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT** To detect fire, run the appropriate cells in the data generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_to_s_join_query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9 - Count FireEvent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "Count_Fire_Event_query = (join_df\n",
    "                     .withWatermark(\"TS\", \"10 minutes\")\n",
    "                     .groupBy(window(\"TS\", \"10 minutes\", \"1 minute\"),\"SENSOR\")\n",
    "                     .count()\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"results\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+------+-----+\n",
      "|window                                    |SENSOR|count|\n",
      "+------------------------------------------+------+-----+\n",
      "|[2020-11-24 14:28:00, 2020-11-24 14:38:00]|S1    |1350 |\n",
      "|[2020-11-24 14:29:00, 2020-11-24 14:39:00]|S1    |2690 |\n",
      "|[2020-11-24 14:30:00, 2020-11-24 14:40:00]|S1    |3995 |\n",
      "|[2020-11-24 14:31:00, 2020-11-24 14:41:00]|S1    |5264 |\n",
      "|[2020-11-24 14:32:00, 2020-11-24 14:42:00]|S1    |6497 |\n",
      "+------------------------------------------+------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM results ORDER BY window\").show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "Count_Fire_Event_query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke_query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "temperature_query.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
