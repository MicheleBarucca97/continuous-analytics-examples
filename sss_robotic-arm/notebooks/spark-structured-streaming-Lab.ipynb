{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Structured Streaming - Demo\n",
    "## Robotic Arm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://774ea6043b75:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f35fd862430>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "import io\n",
    "from pyspark.sql.functions import *\n",
    "import time\n",
    "import json\n",
    "import struct\n",
    "import requests \n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1,org.apache.spark:spark-streaming-kafka-0-10_2.11:2.4.5,org.apache.kafka:kafka-clients:2.6.0 pyspark-shell'\n",
    "                                    \n",
    "spark = (SparkSession.builder \n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"test\")\n",
    "    .getOrCreate()\n",
    "        )\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'RoboticArm'\n",
    "servers = \"kafka:9092\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers in Spark Structured Streaming \n",
    "\n",
    "Please refer to [continuous-analytics-examples/blob/master/epl_robotic-arm/readme.md](https://github.com/quantiaconsulting/continuous-analytics-examples/blob/master/epl_robotic-arm/readme.md) for the EPL version of the following queries.\n",
    "\n",
    "Let's first try with the model proposed for EPL and see what happens. To get the data run [datagen1.ipynb](datagen1.ipynb)\n",
    "\n",
    "### Let's create the streaming Data Frames using the data in the kafka topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "roboticArm_schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"stressLevel\", IntegerType(), True),\n",
    "    StructField(\"ts\", TimestampType(), True)])\n",
    "\n",
    "raw_roboticArm_df = (spark\n",
    "  .readStream\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", servers)\n",
    "  .option(\"startingOffsets\", \"earliest\")\n",
    "  .option(\"subscribe\", topic)\n",
    "  .load())\n",
    "\n",
    "roboticArm_sdf = (raw_roboticArm_df\n",
    "                      .select(from_json(col(\"value\").cast(\"string\"), roboticArm_schema).alias(\"value\"))\n",
    "                      .select(\"value.*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevel: integer (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "roboticArm_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to make sure that it works, let's first inspect the content of the stream "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_query = (roboticArm_sdf\n",
    "    .writeStream\n",
    "    .format(\"memory\") # this is for debug purpose only! DO NOT USE IN PRODUCTION\n",
    "    .queryName(\"sinkTable\")\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the following cell to see the most recent content of the sinkTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+-----------+-------------------+\n",
      "| id|     status|stressLevel|                 ts|\n",
      "+---+-----------+-----------+-------------------+\n",
      "|  1|     moving|          2|2021-10-28 11:54:07|\n",
      "|  2|     moving|          1|2021-10-28 11:54:07|\n",
      "|  2|placingGood|          3|2021-10-28 11:53:59|\n",
      "|  1|placingGood|          3|2021-10-28 11:53:59|\n",
      "|  2| movingGood|          9|2021-10-28 11:53:49|\n",
      "+---+-----------+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sinkTable ORDER BY TS DESC\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do not forget to stop queries that you are not using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E1\n",
    "\n",
    "> Propose how to model the streaming data generated by the robotic arms.\n",
    "\n",
    "Let's first try with the model proposed for EPL and see what happens. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E2\n",
    "\n",
    "> Write a continuous query that emits the max stress for each arm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the SQL sytyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a logic table on top of the streaming data frame\n",
    "roboticArm_sdf.createTempView(\"RoboticArm\") # this time we will not clean it up, because we use it in the next queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"\"\"\n",
    "SELECT id, max(stressLevel) \n",
    "FROM RoboticArm \n",
    "GROUP BY id;\n",
    "\"\"\"\n",
    "\n",
    "# write your query in SQL, register it and start it\n",
    "e2 = (spark.sql(query_string)\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .outputMode(\"complete\") # <-- CHANGE HERE\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+\n",
      "| id|max(stressLevel)|\n",
      "+---+----------------+\n",
      "|  1|               7|\n",
      "|  2|               9|\n",
      "+---+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look up the most recent results\n",
    "spark.sql(\"SELECT * FROM sinkTable\").show(5) # woithout ORDER BY TS DESC because the result in the table is already only the most recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "e2.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The DataFrame style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your query in SQL, register it and start it\n",
    "e2bis = (roboticArm_sdf\n",
    "                     .groupBy(\"id\")\n",
    "                     .max()\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .outputMode(\"complete\") # \n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+\n",
      "| id|max(stressLevel)|\n",
      "+---+----------------+\n",
      "|  1|               8|\n",
      "|  2|               9|\n",
      "+---+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look up the most recent results\n",
    "spark.sql(\"SELECT * FROM sinkTable\").show(5) # woithout ORDER BY TS DESC because the result in the table is already only the most recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "e2bis.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E3\n",
    "\n",
    "> A continuous query that emits the average stress level between a pick (status==goodGrasped) and a place (status==placingGood)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark Structured Streaming does not support the EPL's operator `->` (that reads as *followed by*. We need to use a stream-to-stream join.\n",
    "\n",
    "this is an hard task, let's simplify it\n",
    "\n",
    "### E3.1\n",
    "\n",
    "> A continuous query that emits the events between a moving (status==movingGood) and a place (status==placingGood)\n",
    "\n",
    "NOTE: no request to average and only two consecutive events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a streaming DataFrame with only event wher status='movingGood'\n",
    "moving_sdf = (roboticArm_sdf\n",
    "                .where(\"status='movingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"ts\",\"tsMoving\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a streaming DataFrame with only event wher status='placingGood'\n",
    "\n",
    "placing_sdf = (roboticArm_sdf\n",
    "                .where(\"status='placingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"ts\",\"tsPlacing\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join without the event-time constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_sdf = (moving_sdf.join(\n",
    "  placing_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (tsMoving < tsPlacing )\n",
    "    \"\"\"\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3 = (join_sdf\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+-------------------+---------+-----------+-----------+-------------------+\n",
      "|idMoving|status    |stressLevel|tsMoving           |idPlacing|status     |stressLevel|tsPlacing          |\n",
      "+--------+----------+-----------+-------------------+---------+-----------+-----------+-------------------+\n",
      "|1       |movingGood|7          |2021-10-28 11:53:46|1        |placingGood|3          |2021-10-28 12:36:59|\n",
      "|1       |movingGood|7          |2021-10-28 11:52:40|1        |placingGood|3          |2021-10-28 12:36:59|\n",
      "|1       |movingGood|7          |2021-10-28 11:53:13|1        |placingGood|3          |2021-10-28 12:36:59|\n",
      "|1       |movingGood|7          |2021-10-28 11:52:07|1        |placingGood|3          |2021-10-28 12:36:59|\n",
      "|1       |movingGood|7          |2021-10-28 11:54:52|1        |placingGood|3          |2021-10-28 12:36:59|\n",
      "+--------+----------+-----------+-------------------+---------+-----------+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sinkTable ORDER BY tsPlacing DESC\").show(5,False) # note, I change ts in tsPlacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "Is this what we want?\n",
    "\n",
    "Let's try to count how many joins we have here ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+--------+\n",
      "|idPlacing|tsPlacing          |count(1)|\n",
      "+---------+-------------------+--------+\n",
      "|1        |2021-10-28 12:41:24|90      |\n",
      "|2        |2021-10-28 12:41:24|89      |\n",
      "|2        |2021-10-28 12:40:51|88      |\n",
      "|1        |2021-10-28 12:40:51|89      |\n",
      "|1        |2021-10-28 12:40:18|88      |\n",
      "|2        |2021-10-28 12:40:18|87      |\n",
      "|1        |2021-10-28 12:39:45|87      |\n",
      "|2        |2021-10-28 12:39:45|86      |\n",
      "|2        |2021-10-28 12:39:11|85      |\n",
      "|1        |2021-10-28 12:39:11|86      |\n",
      "|1        |2021-10-28 12:38:38|85      |\n",
      "|2        |2021-10-28 12:38:38|84      |\n",
      "|1        |2021-10-28 12:38:05|84      |\n",
      "|2        |2021-10-28 12:38:05|83      |\n",
      "|2        |2021-10-28 12:37:32|82      |\n",
      "|1        |2021-10-28 12:37:32|83      |\n",
      "|1        |2021-10-28 12:36:59|82      |\n",
      "|2        |2021-10-28 12:36:59|81      |\n",
      "|2        |2021-10-28 12:36:26|80      |\n",
      "|1        |2021-10-28 12:36:26|81      |\n",
      "+---------+-------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT idPlacing, tsPlacing, count(*) FROM sinkTable group by idPlacing, tsPlacing ORDER BY tsPlacing DESC\").show(20,False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Far too many!** ... and growing :-(\n",
    "\n",
    "O-: !!! ... and also **the state is growing** !!! :-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import json\n",
    "while True:\n",
    "    print(json.dumps(e3.lastProgress, indent=4))\n",
    "    print(e3.status)\n",
    "    time.sleep(1)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor for a minute the field `\"numRowsTotal\"` in `\"stateOperators\"`.\n",
    "\n",
    "**We need to add watermarks and a time constraint for state cleanup!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "movingW_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='movingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"ts\",\"tsMoving\")\n",
    "               )\n",
    "\n",
    "placingW_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='placingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"ts\",\"tsPlacing\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinTC_sdf = (movingW_sdf.join(\n",
    "  placingW_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (tsPlacing > tsMoving ) AND\n",
    "    (tsPlacing < tsMoving + interval 14 seconds )\"\"\" # TIME CONSTRAIN ADDED HERE (considering also that the time flows at half of the speed) !!!\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3TC = (joinTC_sdf\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+--------+\n",
      "|idPlacing|tsPlacing          |count(1)|\n",
      "+---------+-------------------+--------+\n",
      "|1        |2021-10-28 12:50:49|1       |\n",
      "|2        |2021-10-28 12:50:49|2       |\n",
      "|2        |2021-10-28 12:50:16|2       |\n",
      "|1        |2021-10-28 12:50:16|1       |\n",
      "|2        |2021-10-28 12:49:43|2       |\n",
      "|1        |2021-10-28 12:49:43|1       |\n",
      "|1        |2021-10-28 12:49:09|1       |\n",
      "|2        |2021-10-28 12:49:09|2       |\n",
      "|2        |2021-10-28 12:48:36|2       |\n",
      "|1        |2021-10-28 12:48:36|1       |\n",
      "|1        |2021-10-28 12:48:03|1       |\n",
      "|2        |2021-10-28 12:48:03|2       |\n",
      "|2        |2021-10-28 12:47:29|2       |\n",
      "|1        |2021-10-28 12:47:29|1       |\n",
      "|1        |2021-10-28 12:46:56|1       |\n",
      "|2        |2021-10-28 12:46:56|2       |\n",
      "|2        |2021-10-28 12:46:23|2       |\n",
      "|1        |2021-10-28 12:46:23|1       |\n",
      "|2        |2021-10-28 12:45:50|2       |\n",
      "|1        |2021-10-28 12:45:50|1       |\n",
      "+---------+-------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT idPlacing, tsPlacing, count(*) FROM sinkTable group by idPlacing, tsPlacing ORDER BY tsPlacing DESC\").show(20,False) # note, I change ts in tsTemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also notice that the state no longer grows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import json\n",
    "while True:\n",
    "    print(json.dumps(e3TC.lastProgress, indent=4))\n",
    "    print(e3TC.status)\n",
    "    time.sleep(1)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3TC.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How much should the watermark and the time constraint be?**\n",
    "\n",
    "|watermark | time constraint | number of results per arm |reason                                         |\n",
    "|----------|-----------------|-------------------|-----------------------------------------------|\n",
    "|  any     |           <=10  |         0         | for each arm, there is no placing within less than 10 sec to a moving |   \n",
    "|  any     |    >10 & < 14   |         1 or 0    | for one of the arms, there is 1 placing within 10-14 sec to a moving        |    \n",
    "|  any     |    >14 & < 44   |         1         | for each arm, there is 1 placing within 10-43 sec to a moving                 \n",
    "|  any     |    >=44 & <48   |         1 or 2    | for one of the arms, there are 2 placing within 44-47 sec to a moving                |   \n",
    "|  any     |          >=48   |         2+        | for each of the arm, there are more than 2 placing within 48 or more sec to a moving                     |   \n",
    "\n",
    "The watermark does not influence the answer because, in this case, the data arrive in order and without any delay, **However it is important to clean the state**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E3.2\n",
    "\n",
    "> A continuous query that emits the events between a **pick (status==goodGrasped)** and a place (status==placingGood)\n",
    "\n",
    "NOTE: I'm adding one more type of event, good grasped that should appear before any moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapsedW_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='goodGrasped'\")\n",
    "                .withColumnRenamed(\"id\",\"idGrasped\")\n",
    "                .withColumnRenamed(\"ts\",\"tsGrasped\")\n",
    "               )\n",
    "\n",
    "movingW_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='movingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"ts\",\"tsMoving\")\n",
    "               )\n",
    "\n",
    "placingW_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='placingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"ts\",\"tsPlacing\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinGM_sdf = (grapsedW_sdf.join(\n",
    "  movingW_sdf, expr(\"\"\"\n",
    "    (idGrasped == idMoving) AND\n",
    "    (tsMoving > tsGrasped ) AND\n",
    "    (tsMoving < tsGrasped + interval 3 seconds )\"\"\" # TIME CONSTRAIN ADDED HERE (considering also that the time flows at half of the speed) !!!\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- idGrasped: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevel: integer (nullable = true)\n",
      " |-- tsGrasped: timestamp (nullable = true)\n",
      " |-- idMoving: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevel: integer (nullable = true)\n",
      " |-- tsMoving: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinGM_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- idPlacing: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevel: integer (nullable = true)\n",
      " |-- tsPlacing: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "placingW_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinGMP_sdf = (joinGM_sdf.join(\n",
    "  placingW_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (tsPlacing > tsMoving ) AND\n",
    "    (tsPlacing < tsMoving + interval 14 seconds )\"\"\" # TIME CONSTRAIN ADDED HERE (considering also that the time flows at half of the speed) !!!\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3_2 = (joinGMP_sdf\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----------+-----------+-------------------+--------+----------+-----------+-------------------+---------+-----------+-----------+-------------------+\n",
      "|idGrasped|status     |stressLevel|tsGrasped          |idMoving|status    |stressLevel|tsMoving           |idPlacing|status     |stressLevel|tsPlacing          |\n",
      "+---------+-----------+-----------+-------------------+--------+----------+-----------+-------------------+---------+-----------+-----------+-------------------+\n",
      "|2        |goodGrasped|5          |2021-10-28 13:14:24|2       |movingGood|9          |2021-10-28 13:14:25|2        |placingGood|3          |2021-10-28 13:14:35|\n",
      "|1        |goodGrasped|1          |2021-10-28 13:14:20|1       |movingGood|8          |2021-10-28 13:14:22|1        |placingGood|3          |2021-10-28 13:14:35|\n",
      "|2        |goodGrasped|5          |2021-10-28 13:13:50|2       |movingGood|9          |2021-10-28 13:13:51|2        |placingGood|3          |2021-10-28 13:14:01|\n",
      "|1        |goodGrasped|1          |2021-10-28 13:13:46|1       |movingGood|8          |2021-10-28 13:13:48|1        |placingGood|3          |2021-10-28 13:14:01|\n",
      "|2        |goodGrasped|5          |2021-10-28 13:13:17|2       |movingGood|9          |2021-10-28 13:13:18|2        |placingGood|3          |2021-10-28 13:13:28|\n",
      "|1        |goodGrasped|1          |2021-10-28 13:13:13|1       |movingGood|8          |2021-10-28 13:13:15|1        |placingGood|3          |2021-10-28 13:13:28|\n",
      "|2        |goodGrasped|5          |2021-10-28 13:12:44|2       |movingGood|9          |2021-10-28 13:12:45|2        |placingGood|3          |2021-10-28 13:12:55|\n",
      "|1        |goodGrasped|1          |2021-10-28 13:12:40|1       |movingGood|8          |2021-10-28 13:12:42|1        |placingGood|3          |2021-10-28 13:12:55|\n",
      "|2        |goodGrasped|5          |2021-10-28 13:12:11|2       |movingGood|9          |2021-10-28 13:12:12|2        |placingGood|3          |2021-10-28 13:12:22|\n",
      "|1        |goodGrasped|1          |2021-10-28 13:12:07|1       |movingGood|8          |2021-10-28 13:12:09|1        |placingGood|3          |2021-10-28 13:12:22|\n",
      "|2        |goodGrasped|5          |2021-10-28 13:11:38|2       |movingGood|9          |2021-10-28 13:11:39|2        |placingGood|3          |2021-10-28 13:11:49|\n",
      "|1        |goodGrasped|1          |2021-10-28 13:11:34|1       |movingGood|8          |2021-10-28 13:11:36|1        |placingGood|3          |2021-10-28 13:11:49|\n",
      "|2        |goodGrasped|5          |2021-10-28 13:11:05|2       |movingGood|9          |2021-10-28 13:11:06|2        |placingGood|3          |2021-10-28 13:11:16|\n",
      "|1        |goodGrasped|1          |2021-10-28 13:11:01|1       |movingGood|8          |2021-10-28 13:11:03|1        |placingGood|3          |2021-10-28 13:11:16|\n",
      "|2        |goodGrasped|5          |2021-10-28 13:10:32|2       |movingGood|9          |2021-10-28 13:10:33|2        |placingGood|3          |2021-10-28 13:10:43|\n",
      "|1        |goodGrasped|1          |2021-10-28 13:10:28|1       |movingGood|8          |2021-10-28 13:10:30|1        |placingGood|3          |2021-10-28 13:10:43|\n",
      "|2        |goodGrasped|5          |2021-10-28 13:09:59|2       |movingGood|9          |2021-10-28 13:10:00|2        |placingGood|3          |2021-10-28 13:10:10|\n",
      "|1        |goodGrasped|1          |2021-10-28 13:09:55|1       |movingGood|8          |2021-10-28 13:09:57|1        |placingGood|3          |2021-10-28 13:10:10|\n",
      "|2        |goodGrasped|5          |2021-10-28 13:09:26|2       |movingGood|9          |2021-10-28 13:09:27|2        |placingGood|3          |2021-10-28 13:09:37|\n",
      "|1        |goodGrasped|1          |2021-10-28 13:09:22|1       |movingGood|8          |2021-10-28 13:09:24|1        |placingGood|3          |2021-10-28 13:09:37|\n",
      "+---------+-----------+-----------+-------------------+--------+----------+-----------+-------------------+---------+-----------+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sinkTable ORDER BY tsGrasped DESC\").show(20,False) # note, I change ts in tsTemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3_2.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E3.3\n",
    "\n",
    "> A continuous query that emits **the average stress level** between a pick (status==goodGrasped) and a place (status==placingGood)\n",
    "\n",
    "NOTE: the original question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapsedFinal_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='goodGrasped'\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelGrasped\")\n",
    "                .withColumnRenamed(\"id\",\"idGrasped\")\n",
    "                .withColumnRenamed(\"ts\",\"tsGrasped\")\n",
    "               )\n",
    "\n",
    "movingFinal_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='movingGood'\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelMoving\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"ts\",\"tsMoving\")\n",
    "               )\n",
    "\n",
    "placingFinal_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='placingGood'\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelPlacing\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"ts\",\"tsPlacing\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- idPlacing: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevelPlacing: integer (nullable = true)\n",
      " |-- tsPlacing: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "placingFinal_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinFinal_sdf = (grapsedFinal_sdf.join(\n",
    "  movingFinal_sdf, expr(\"\"\"\n",
    "    (idGrasped == idMoving) AND\n",
    "    (tsMoving > tsGrasped ) AND\n",
    "    (tsMoving < tsGrasped + interval 3 seconds )\"\"\" \n",
    "    )).join(\n",
    "  placingFinal_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (tsPlacing > tsMoving ) AND\n",
    "    (tsPlacing < tsMoving + interval 14 seconds )\"\"\"\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- idGrasped: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevelGrasped: integer (nullable = true)\n",
      " |-- tsGrasped: timestamp (nullable = true)\n",
      " |-- idMoving: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevelMoving: integer (nullable = true)\n",
      " |-- tsMoving: timestamp (nullable = true)\n",
      " |-- idPlacing: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevelPlacing: integer (nullable = true)\n",
      " |-- tsPlacing: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinFinal_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_sdf = joinFinal_sdf.select(col(\"idGrasped\").alias(\"id\"), expr(\"(stressLevelGrasped+stressLevelMoving+stressLevelPlacing)/3 AS AVG_stressLevel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3_3 = (final_sdf\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|id |AVG_stressLevel   |\n",
      "+---+------------------+\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "+---+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sinkTable\").show(20,False) # note, I change ts in tsTemp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3_3.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Think out of the box!!!\n",
    "\n",
    "**Is the complexity of temporal joins acceptable? Is there any other solution that does not require them?**\n",
    "\n",
    "In many cases, query answering is hard because the datamodel is **over simplified**.\n",
    "\n",
    "We may go back to E1 problem and propose to change the model so to eliminate the need for a temporal join. A sequential number for the cycles of each arm would be enough to make the join deterministic. See [datagen2.ipynb](datagen1.ipynb) for the changes in the data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- cycle: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevel: integer (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "roboticArmV2_schema = StructType([             ## <-- CHANGE HERE new name for the schema\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"cycle\", IntegerType(), True), ## <-- CHANGE HERE new field \n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"stressLevel\", IntegerType(), True),\n",
    "    StructField(\"ts\", TimestampType(), True)])\n",
    "\n",
    "raw_roboticArmV2_df = (spark                   ## <-- CHANGE HERE new name for the df\n",
    "  .readStream\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", servers)\n",
    "  .option(\"startingOffsets\", \"earliest\")\n",
    "  .option(\"subscribe\", \"RoboticArmV2\") ## <-- CHANGE HERE different topic\n",
    "  .load())\n",
    "\n",
    "roboticArmV2_sdf = (raw_roboticArmV2_df      ## <-- CHANGE HERE new name sdf\n",
    "                      .select(from_json(col(\"value\").cast(\"string\"), roboticArmV2_schema).alias(\"value\")) ## <-- CHANGE HERE new schema\n",
    "                      .select(\"value.*\"))\n",
    "\n",
    "roboticArmV2_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "grapsedFinalCyc_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") \n",
    "                .where(\"status='goodGrasped'\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelGrasped\")\n",
    "                .withColumnRenamed(\"id\",\"idGrasped\")\n",
    "                .withColumnRenamed(\"cycle\",\"cycleGrasped\")\n",
    "               )\n",
    "\n",
    "movingFinalCyc_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") \n",
    "                .where(\"status='movingGood'\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelMoving\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"cycle\",\"cycleMoving\")\n",
    "               )\n",
    "\n",
    "placingFinalCyc_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") \n",
    "                .where(\"status='placingGood'\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelPlacing\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"cycle\",\"cyclePlacing\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinFinalCyc_sdf = (grapsedFinalCyc_sdf.join(\n",
    "  movingFinalCyc_sdf, expr(\"\"\"\n",
    "    (idGrasped == idMoving) AND\n",
    "    (cycleGrasped == cycleMoving )\"\"\" ## <- CHANGE HERE  \n",
    "    )).join(\n",
    "  placingFinalCyc_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (cycleMoving == cyclePlacing)\"\"\" ## <- CHANGE HERE \n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinV2_sdf = (movingV2_sdf.join(\n",
    "  placingV2_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (cyclePlacing == cycleMoving )\"\"\" ## <- CHANGE HERE \n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalCyc_sdf = joinFinalCyc_sdf.select(col(\"idGrasped\").alias(\"id\"), expr(\"(stressLevelGrasped+stressLevelMoving+stressLevelPlacing)/3 AS AVG_stressLevel\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3V2 = (finalCyc_sdf\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|id |AVG_stressLevel   |\n",
      "+---+------------------+\n",
      "|2  |5.666666666666667 |\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|2  |5.666666666666667 |\n",
      "|1  |3.6666666666666665|\n",
      "|2  |5.666666666666667 |\n",
      "|1  |3.6666666666666665|\n",
      "|2  |5.666666666666667 |\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|1  |3.6666666666666665|\n",
      "|2  |5.666666666666667 |\n",
      "|1  |3.6666666666666665|\n",
      "|2  |5.666666666666667 |\n",
      "|1  |3.6666666666666665|\n",
      "|2  |5.666666666666667 |\n",
      "|2  |5.666666666666667 |\n",
      "|2  |5.666666666666667 |\n",
      "|1  |3.6666666666666665|\n",
      "|2  |5.666666666666667 |\n",
      "+---+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sinkTable\").show(20,False) # note, I change ts in tsTemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Much easier** !!\n",
    "\n",
    "**REMEMBER**: modeling and querying are *two sides of the same coin*\n",
    "\n",
    "We are not in a traditional RDBMS where modeling is done once for all by the DB administrator and queries must conform to \"the model\". We are in a setting where performance matters more than governance and chaning the model is often the only way to keep good performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3V2.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E4\n",
    "\n",
    ">A continuous query that returns the robotic arms that,\n",
    ">\n",
    "> * in less than 20 second (was 10 in EPL, but here the time passes at half of the speed),\n",
    "> * picked a good while safely operating,\n",
    "> * moved it while the controller was raising a warning, and\n",
    "> * placed it while safely operating again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodGraspedSafely_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\")\n",
    "                .where(\"status='goodGrasped' AND stressLevel < 7\")\n",
    "                .withColumnRenamed(\"id\",\"idGrasped\")\n",
    "                .withColumnRenamed(\"cycle\",\"cycleGrasped\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelGrasped\")\n",
    "                .withColumnRenamed(\"ts\",\"tsGrasped\")\n",
    "               )\n",
    "\n",
    "movingWarning_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\")\n",
    "                .where(\"status='movingGood' AND stressLevel > 6 AND stressLevel < 9\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"cycle\",\"cycleMoving\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelMoving\")\n",
    "                .withColumnRenamed(\"ts\",\"tsMoving\")\n",
    "               )\n",
    "\n",
    "placingSafely_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\")\n",
    "                .where(\"status='placingGood' AND stressLevel < 7\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"cycle\",\"cyclePlacing\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelPlacing\")\n",
    "                .withColumnRenamed(\"ts\",\"tsPlacing\")\n",
    "               )\n",
    "\n",
    "join1_sdf = (goodGraspedSafely_sdf.join(\n",
    "    movingWarning_sdf, expr(\"\"\"\n",
    "    (idGrasped == idMoving) AND\n",
    "    (cycleGrasped == cycleMoving)\"\"\" \n",
    "    )))\n",
    "\n",
    "join2_sdf = (join1_sdf.join(\n",
    "  placingSafely_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (cyclePlacing == cycleMoving )\"\"\" \n",
    "    )))\n",
    "\n",
    "within20sec = join2_sdf.where(\"tsPlacing <= tsGrasped + interval 20 seconds\")\n",
    "\n",
    "e4 = (within20sec\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|ID |cycle|\n",
      "+---+-----+\n",
      "|1  |24   |\n",
      "|1  |23   |\n",
      "|1  |22   |\n",
      "|1  |21   |\n",
      "|1  |20   |\n",
      "+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT idGrasped AS ID, cyclePlacing AS cycle FROM sinkTable ORDER BY cyclePlacing DESC\").show(5,False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indeed only the arm whose ID is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "e4.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E5\n",
    "\n",
    "> A continuous query that monitors the results of the previous one (i.e., E4) and counts how many times each robotic arm is present in the stream over a window of 20 seconds updating the counting every 4 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- idGrasped: string (nullable = true)\n",
      " |-- cycleGrasped: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevelGrasped: integer (nullable = true)\n",
      " |-- tsGrasped: timestamp (nullable = true)\n",
      " |-- idMoving: string (nullable = true)\n",
      " |-- cycleMoving: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevelMoving: integer (nullable = true)\n",
      " |-- tsMoving: timestamp (nullable = true)\n",
      " |-- idPlacing: string (nullable = true)\n",
      " |-- cyclePlacing: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevelPlacing: integer (nullable = true)\n",
      " |-- tsPlacing: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "within20sec.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "e5 = (within20sec\n",
    "                     .withWatermark(\"tsPlacing\", \"1 minutes\")\n",
    "                     .groupBy(window(\"tsPlacing\", \"40 seconds\", \"8 seconds\"),\"idGrasped\")\n",
    "                     .count()\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\") \n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+---------+-----+\n",
      "|window                                    |idGrasped|count|\n",
      "+------------------------------------------+---------+-----+\n",
      "|[2021-10-28 14:00:40, 2021-10-28 14:01:20]|1        |1    |\n",
      "|[2021-10-28 14:00:32, 2021-10-28 14:01:12]|1        |1    |\n",
      "|[2021-10-28 14:00:24, 2021-10-28 14:01:04]|1        |2    |\n",
      "|[2021-10-28 14:00:16, 2021-10-28 14:00:56]|1        |1    |\n",
      "|[2021-10-28 14:00:08, 2021-10-28 14:00:48]|1        |1    |\n",
      "|[2021-10-28 14:00:00, 2021-10-28 14:00:40]|1        |1    |\n",
      "|[2021-10-28 13:59:52, 2021-10-28 14:00:32]|1        |2    |\n",
      "|[2021-10-28 13:59:44, 2021-10-28 14:00:24]|1        |1    |\n",
      "|[2021-10-28 13:59:36, 2021-10-28 14:00:16]|1        |1    |\n",
      "|[2021-10-28 13:59:28, 2021-10-28 14:00:08]|1        |1    |\n",
      "+------------------------------------------+---------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sinkTable ORDER BY window DESC\").show(10,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "e5.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
