{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Structured Streaming - Demo\n",
    "## Fire alarm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://7617fb559195:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>test</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc5be0b64f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.streaming import StreamingContext\n",
    "import io\n",
    "from pyspark.sql.functions import *\n",
    "import time\n",
    "import json\n",
    "import struct\n",
    "import requests \n",
    "\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1,org.apache.spark:spark-streaming-kafka-0-10_2.11:2.4.5,org.apache.kafka:kafka-clients:2.6.0 pyspark-shell'\n",
    "                                    \n",
    "spark = (SparkSession.builder \n",
    "    .master(\"local[*]\")\n",
    "    .appName(\"test\")\n",
    "    .getOrCreate()\n",
    "        )\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up the environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic = 'RoboticArm'\n",
    "servers = \"kafka:9092\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers in Spark Structured Streaming \n",
    "\n",
    "Please refer to [continuous-analytics-examples/blob/master/epl_robotic-arm/readme.md](https://github.com/quantiaconsulting/continuous-analytics-examples/blob/master/epl_robotic-arm/readme.md) for the EPL version of the following queries.\n",
    "\n",
    "### Let's create the streaming Data Frames using the data in the kafka topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "roboticArm_schema = StructType([\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"stressLevel\", IntegerType(), True),\n",
    "    StructField(\"ts\", TimestampType(), True)])\n",
    "\n",
    "raw_roboticArm_df = (spark\n",
    "  .readStream\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", servers)\n",
    "  .option(\"startingOffsets\", \"earliest\")\n",
    "  .option(\"subscribe\", topic)\n",
    "  .load())\n",
    "\n",
    "roboticArm_sdf = (raw_roboticArm_df\n",
    "                      .select(from_json(col(\"value\").cast(\"string\"), roboticArm_schema).alias(\"value\"))\n",
    "                      .select(\"value.*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevel: integer (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "roboticArm_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to make sure that it works, let's first inspect the content of the stream "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_query = (roboticArm_sdf\n",
    "    .writeStream\n",
    "    .format(\"memory\") # this is for debug purpose only! DO NOT USE IN PRODUCTION\n",
    "    .queryName(\"sinkTable\")\n",
    "    .start())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the following cell to see the most recent content of the sinkTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+-----------+---+\n",
      "| id|status|stressLevel| ts|\n",
      "+---+------+-----------+---+\n",
      "+---+------+-----------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sinkTable ORDER BY TS DESC\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do not forget to stop queries that you are not using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_query.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E1\n",
    "\n",
    "> Propose how to model the streaming data generated by the robotic arms.\n",
    "\n",
    "Let's first try with the model proposed for EPL and see what happens. To get the data run [datagen1.ipynb](datagen1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E2\n",
    "\n",
    "> Write a continuous query that emits the max stress for each arm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### the SQL sytyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a logic table on top of the streaming data frame\n",
    "roboticArm_sdf.createTempView(\"RoboticArm\") # this time we will not clean it up, because we use it in the next queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_string = \"\"\"\n",
    "SELECT id, max(stressLevel) \n",
    "FROM RoboticArm \n",
    "GROUP BY id;\n",
    "\"\"\"\n",
    "\n",
    "# write your query in SQL, register it and start it\n",
    "e2 = (spark.sql(query_string)\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .outputMode(\"complete\") # <-- CHANGE HERE\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+\n",
      "| id|max(stressLevel)|\n",
      "+---+----------------+\n",
      "|  1|               7|\n",
      "|  2|               9|\n",
      "+---+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look up the most recent results\n",
    "spark.sql(\"SELECT * FROM sinkTable\").show(5) # woithout ORDER BY TS DESC because the result in the table is already only the most recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "e2.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The DataFrame style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your query in SQL, register it and start it\n",
    "e2bis = (roboticArm_sdf\n",
    "                     .groupBy(\"id\")\n",
    "                     .max()\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .outputMode(\"complete\") # \n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------------+\n",
      "| id|max(stressLevel)|\n",
      "+---+----------------+\n",
      "|  1|               7|\n",
      "|  2|               9|\n",
      "+---+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look up the most recent results\n",
    "spark.sql(\"SELECT * FROM sinkTable\").show(5) # woithout ORDER BY TS DESC because the result in the table is already only the most recent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up\n",
    "e2bis.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E3\n",
    "\n",
    "> A continuous query that emits the average stress level between a pick (status==goodGrasped) and a place (status==placingGood)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark Structured Streaming does not support the EPL's operator `->` (that reads as *followed by*. We need to use a stream-to-stream join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply the two filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "moving_sdf = (roboticArm_sdf\n",
    "                .where(\"status='movingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"ts\",\"tsMoving\")\n",
    "               )\n",
    "\n",
    "placing_sdf = (roboticArm_sdf\n",
    "                .where(\"status='placingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"ts\",\"tsPlacing\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join without the event-time constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "join_sdf = (moving_sdf.join(\n",
    "  placing_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (tsPlacing > tsMoving )\n",
    "    \"\"\"\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3 = (join_sdf\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------+-------------------+---------+-----------+-----------+-------------------+\n",
      "|idMoving|status    |stressLevel|tsMoving           |idPlacing|status     |stressLevel|tsPlacing          |\n",
      "+--------+----------+-----------+-------------------+---------+-----------+-----------+-------------------+\n",
      "|1       |movingGood|7          |2021-10-18 14:23:46|1        |placingGood|3          |2021-10-18 14:39:27|\n",
      "|1       |movingGood|7          |2021-10-18 14:22:40|1        |placingGood|3          |2021-10-18 14:39:27|\n",
      "|1       |movingGood|7          |2021-10-18 14:23:13|1        |placingGood|3          |2021-10-18 14:39:27|\n",
      "|1       |movingGood|7          |2021-10-18 14:22:07|1        |placingGood|3          |2021-10-18 14:39:27|\n",
      "|1       |movingGood|7          |2021-10-18 14:24:53|1        |placingGood|3          |2021-10-18 14:39:27|\n",
      "+--------+----------+-----------+-------------------+---------+-----------+-----------+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sinkTable ORDER BY tsPlacing DESC\").show(5,False) # note, I change ts in tsPlacing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Discussion\n",
    "\n",
    "Is this what we want?\n",
    "\n",
    "Let's try to count how many joins we have here ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+--------+\n",
      "|idPlacing|tsPlacing          |count(1)|\n",
      "+---------+-------------------+--------+\n",
      "|2        |2021-10-18 14:39:27|32      |\n",
      "|1        |2021-10-18 14:39:27|32      |\n",
      "|1        |2021-10-18 14:38:54|31      |\n",
      "|2        |2021-10-18 14:38:54|31      |\n",
      "|1        |2021-10-18 14:38:21|30      |\n",
      "+---------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT idPlacing, tsPlacing, count(*) FROM sinkTable group by idPlacing, tsPlacing ORDER BY tsPlacing DESC\").show(5,False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Far too many!** ... and growing :-(\n",
    "\n",
    "O-: !!! ... and also **the state is growing** !!! :-O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"04a82c05-6b97-47f0-950d-b3f327e156c2\",\n",
      "    \"runId\": \"6d45211d-905a-4eb8-a7f3-511a6e2c2c4f\",\n",
      "    \"name\": \"sinkTable\",\n",
      "    \"timestamp\": \"2021-10-18T14:40:21.646Z\",\n",
      "    \"batchId\": 91,\n",
      "    \"numInputRows\": 8,\n",
      "    \"inputRowsPerSecond\": 1.5488867376573088,\n",
      "    \"processedRowsPerSecond\": 1.8289894833104712,\n",
      "    \"durationMs\": {\n",
      "        \"addBatch\": 4251,\n",
      "        \"getBatch\": 0,\n",
      "        \"latestOffset\": 1,\n",
      "        \"queryPlanning\": 89,\n",
      "        \"triggerExecution\": 4374,\n",
      "        \"walCommit\": 13\n",
      "    },\n",
      "    \"stateOperators\": [\n",
      "        {\n",
      "            \"numRowsTotal\": 133,\n",
      "            \"numRowsUpdated\": 1,\n",
      "            \"memoryUsedBytes\": 362176,\n",
      "            \"customMetrics\": {\n",
      "                \"loadedMapCacheHitCount\": 36400,\n",
      "                \"loadedMapCacheMissCount\": 0,\n",
      "                \"stateOnCurrentVersionSizeBytes\": 70200\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"sources\": [\n",
      "        {\n",
      "            \"description\": \"KafkaV2[Subscribe[RoboticArm]]\",\n",
      "            \"startOffset\": {\n",
      "                \"RoboticArm\": {\n",
      "                    \"0\": 396\n",
      "                }\n",
      "            },\n",
      "            \"endOffset\": {\n",
      "                \"RoboticArm\": {\n",
      "                    \"0\": 400\n",
      "                }\n",
      "            },\n",
      "            \"numInputRows\": 8,\n",
      "            \"inputRowsPerSecond\": 1.5488867376573088,\n",
      "            \"processedRowsPerSecond\": 1.8289894833104712\n",
      "        }\n",
      "    ],\n",
      "    \"sink\": {\n",
      "        \"description\": \"MemorySink\",\n",
      "        \"numOutputRows\": 0\n",
      "    }\n",
      "}\n",
      "{'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-318287e46966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlastProgress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import json\n",
    "while True:\n",
    "    print(json.dumps(e3.lastProgress, indent=4))\n",
    "    print(e3.status)\n",
    "    time.sleep(1)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Monitor for a minute the field `\"numRowsTotal\"` in `\"stateOperators\"`.\n",
    "\n",
    "**We need to add watermarks and a time constraint for state cleanup!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movingW_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='movingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"ts\",\"tsMoving\")\n",
    "               )\n",
    "\n",
    "placingW_sdf = (roboticArm_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\") # WATERMARK ADDED HERE\n",
    "                .where(\"status='placingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"ts\",\"tsPlacing\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinTC_sdf = (movingW_sdf.join(\n",
    "  placingW_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (tsPlacing > tsMoving ) AND\n",
    "    (tsPlacing < tsMoving + interval 14 seconds )\"\"\" # TIME CONSTRAIN ADDED HERE (considering also that the time flows at half of the speed) !!!\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3TC = (joinTC_sdf\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------------+--------+\n",
      "|idPlacing|tsPlacing          |count(1)|\n",
      "+---------+-------------------+--------+\n",
      "|1        |2021-10-18 15:30:49|1       |\n",
      "|2        |2021-10-18 15:30:49|1       |\n",
      "|2        |2021-10-18 15:30:16|1       |\n",
      "|1        |2021-10-18 15:30:16|1       |\n",
      "|2        |2021-10-18 15:29:43|1       |\n",
      "+---------+-------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT idPlacing, tsPlacing, count(*) FROM sinkTable group by idPlacing, tsPlacing ORDER BY tsPlacing DESC\").show(5,False) # note, I change ts in tsTemp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "also notice that the state no longer grows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"6ba4e4af-2405-4485-b920-169c89c38116\",\n",
      "    \"runId\": \"0aba5bda-450d-4459-9220-d4ec79a27897\",\n",
      "    \"name\": \"sinkTable\",\n",
      "    \"timestamp\": \"2021-10-18T15:31:00.289Z\",\n",
      "    \"batchId\": 48,\n",
      "    \"numInputRows\": 4,\n",
      "    \"inputRowsPerSecond\": 0.6189076280365156,\n",
      "    \"processedRowsPerSecond\": 0.537345513164965,\n",
      "    \"durationMs\": {\n",
      "        \"addBatch\": 7258,\n",
      "        \"getBatch\": 0,\n",
      "        \"latestOffset\": 2,\n",
      "        \"queryPlanning\": 129,\n",
      "        \"triggerExecution\": 7444,\n",
      "        \"walCommit\": 32\n",
      "    },\n",
      "    \"eventTime\": {\n",
      "        \"watermark\": \"2021-10-18T15:29:39.000Z\"\n",
      "    },\n",
      "    \"stateOperators\": [\n",
      "        {\n",
      "            \"numRowsTotal\": 12,\n",
      "            \"numRowsUpdated\": 0,\n",
      "            \"memoryUsedBytes\": 331008,\n",
      "            \"customMetrics\": {\n",
      "                \"loadedMapCacheHitCount\": 19200,\n",
      "                \"loadedMapCacheMissCount\": 0,\n",
      "                \"stateOnCurrentVersionSizeBytes\": 38400\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"sources\": [\n",
      "        {\n",
      "            \"description\": \"KafkaV2[Subscribe[RoboticArm]]\",\n",
      "            \"startOffset\": {\n",
      "                \"RoboticArm\": {\n",
      "                    \"0\": 1496\n",
      "                }\n",
      "            },\n",
      "            \"endOffset\": {\n",
      "                \"RoboticArm\": {\n",
      "                    \"0\": 1498\n",
      "                }\n",
      "            },\n",
      "            \"numInputRows\": 4,\n",
      "            \"inputRowsPerSecond\": 0.6189076280365156,\n",
      "            \"processedRowsPerSecond\": 0.537345513164965\n",
      "        }\n",
      "    ],\n",
      "    \"sink\": {\n",
      "        \"description\": \"MemorySink\",\n",
      "        \"numOutputRows\": 0\n",
      "    }\n",
      "}\n",
      "{'message': 'Processing new data', 'isDataAvailable': True, 'isTriggerActive': True}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-45ff73b5502d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me3TC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlastProgress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me3TC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import json\n",
    "while True:\n",
    "    print(json.dumps(e3TC.lastProgress, indent=4))\n",
    "    print(e3TC.status)\n",
    "    time.sleep(1)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3TC.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How much should the watermark and the time constraint be?**\n",
    "\n",
    "|watermark | time constraint | number of results per arm |reason                                         |\n",
    "|----------|-----------------|-------------------|-----------------------------------------------|\n",
    "|  any     |           <=10  |         0         | for each arm, there is no placing within less than 10 sec to a moving |   \n",
    "|  any     |    >10 & < 14   |         1 or 0    | for one of the arms, there is 1 placing within 10-14 sec to a moving        |    \n",
    "|  any     |    >14 & < 44   |         1         | for each arm, there is 1 placing within 10-43 sec to a moving                 \n",
    "|  any     |    >=44 & <48   |         1 or 2    | for one of the arms, there are 2 placing within 44-47 sec to a moving                |   \n",
    "|  any     |          >=48   |         2+        | for each of the arm, there are more than 2 placing within 48 or more sec to a moving                     |   \n",
    "\n",
    "The watermark does not influence the answer because, in this case, the data arrive in order and without any delay, **However it is important to clean the state**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Is this acceptable? Is there any other solution?**\n",
    "\n",
    "In many cases, query answering is hard because the datamodel is over simplified.\n",
    "\n",
    "We may go back to E1 problem and propose to change the model so to eliminate the need for a temporal join. A sequential number for the cycles of each arm would be enough to make the join deterministic. See [datagen2.ipynb](datagen1.ipynb) for the changes in the data generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- cycle: integer (nullable = true)\n",
      " |-- status: string (nullable = true)\n",
      " |-- stressLevel: integer (nullable = true)\n",
      " |-- ts: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "roboticArmV2_schema = StructType([             ## <-- CHANGE HERE new name for the schema\n",
    "    StructField(\"id\", StringType(), True),\n",
    "    StructField(\"cycle\", IntegerType(), True), ## <-- CHANGE HERE new field \n",
    "    StructField(\"status\", StringType(), True),\n",
    "    StructField(\"stressLevel\", IntegerType(), True),\n",
    "    StructField(\"ts\", TimestampType(), True)])\n",
    "\n",
    "raw_roboticArmV2_df = (spark                   ## <-- CHANGE HERE new name for the df\n",
    "  .readStream\n",
    "  .format(\"kafka\")\n",
    "  .option(\"kafka.bootstrap.servers\", servers)\n",
    "  .option(\"startingOffsets\", \"earliest\")\n",
    "  .option(\"subscribe\", \"RoboticArmV2\") ## <-- CHANGE HERE different topic\n",
    "  .load())\n",
    "\n",
    "roboticArmV2_sdf = (raw_roboticArmV2_df      ## <-- CHANGE HERE new name sdf\n",
    "                      .select(from_json(col(\"value\").cast(\"string\"), roboticArmV2_schema).alias(\"value\")) ## <-- CHANGE HERE new schema\n",
    "                      .select(\"value.*\"))\n",
    "\n",
    "roboticArmV2_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "movingV2_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\")\n",
    "                .where(\"status='movingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"cycle\",\"cycleMoving\")\n",
    "               )\n",
    "\n",
    "placingV2_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\")\n",
    "                .where(\"status='placingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"cycle\",\"cyclePlacing\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "joinV2_sdf = (movingV2_sdf.join(\n",
    "  placingV2_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (cyclePlacing == cycleMoving )\"\"\" ## <- CHANGE HERE \n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3V2 = (joinV2_sdf\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+--------+\n",
      "|idPlacing|cyclePlacing|count(1)|\n",
      "+---------+------------+--------+\n",
      "|2        |4           |1       |\n",
      "|1        |4           |1       |\n",
      "|1        |3           |1       |\n",
      "|2        |3           |1       |\n",
      "|2        |2           |1       |\n",
      "+---------+------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT idPlacing, cyclePlacing, count(*) FROM sinkTable group by idPlacing, cyclePlacing ORDER BY cyclePlacing DESC\").show(5,False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import json\n",
    "while True:\n",
    "    print(json.dumps(e3V2.lastProgress, indent=4))\n",
    "    print(e3V2.status)\n",
    "    time.sleep(1)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Much easier** !!\n",
    "\n",
    "**REMEMBER**: modeling and querying are *two sides of the same coin*\n",
    "\n",
    "We are not in a traditional RDBMS where modeling is done once for all by the DB administrator and queries must conform to \"the model\". We are in a setting where performance matters more than governance and chaning the model is often the only way to keep good performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3V2.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ok, let's now get the work done, because ourt goal was: \n",
    "> A continuous query that emits the average stress level between a pick (status==goodGrasped) and a place (status==placingGood)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodGrasped_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\")\n",
    "                .where(\"status='goodGrasped'\")\n",
    "                .withColumnRenamed(\"id\",\"idGrasped\")\n",
    "                .withColumnRenamed(\"cycle\",\"cycleGrasped\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelGrasped\")\n",
    "               )\n",
    "\n",
    "movingV3_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\")\n",
    "                .where(\"status='movingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"cycle\",\"cycleMoving\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelMoving\")\n",
    "               )\n",
    "\n",
    "placingV3_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\")\n",
    "                .where(\"status='placingGood'\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"cycle\",\"cyclePlacing\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelPlacing\")\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join1_sdf = (goodGrasped_sdf.join(\n",
    "    movingV3_sdf, expr(\"\"\"\n",
    "    (idGrasped == idMoving) AND\n",
    "    (cycleGrasped == cycleMoving)\"\"\" \n",
    "    )))\n",
    "\n",
    "join2_sdf = (join1_sdf.join(\n",
    "  placingV3_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (cyclePlacing == cycleMoving )\"\"\" \n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "join2_sdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = (join2_sdf.select(col(\"idPlacing\").alias(\"ID\"),\n",
    "                         col(\"cyclePlacing\").alias(\"cycle\"),\n",
    "                         expr(\"(stressLevelGrasped + stressLevelMoving + stressLevelPlacing)/3 AS AvgStressLevel\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e3V3 = (avg\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT * FROM sinkTable ORDER BY cycle DESC\").show(5,False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import json\n",
    "while True:\n",
    "    print(json.dumps(e3TC.lastProgress, indent=4))\n",
    "    print(e3TC.status)\n",
    "    time.sleep(1)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'e3V3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-81eb9e82b5a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me3V3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'e3V3' is not defined"
     ]
    }
   ],
   "source": [
    "e3V3.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E4\n",
    "\n",
    ">A continuous query that returns the robotic arms that,\n",
    ">\n",
    "> * in less than 20 second (was 10 in EPL, but here the time passes at half of the speed),\n",
    "> * picked a good while safely operating,\n",
    "> * moved it while the controller was raising a warning, and\n",
    "> * placed it while safely operating again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "goodGraspedSafely_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\")\n",
    "                .where(\"status='goodGrasped' AND stressLevel < 7\")\n",
    "                .withColumnRenamed(\"id\",\"idGrasped\")\n",
    "                .withColumnRenamed(\"cycle\",\"cycleGrasped\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelGrasped\")\n",
    "                .withColumnRenamed(\"ts\",\"tsGrasped\")\n",
    "               )\n",
    "\n",
    "movingWarning_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\")\n",
    "                .where(\"status='movingGood' AND stressLevel > 6 AND stressLevel < 9\")\n",
    "                .withColumnRenamed(\"id\",\"idMoving\")\n",
    "                .withColumnRenamed(\"cycle\",\"cycleMoving\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelMoving\")\n",
    "                .withColumnRenamed(\"ts\",\"tsMoving\")\n",
    "               )\n",
    "\n",
    "placingSafely_sdf = (roboticArmV2_sdf\n",
    "                .withWatermark(\"ts\",\"1 minute\")\n",
    "                .where(\"status='placingGood' AND stressLevel < 7\")\n",
    "                .withColumnRenamed(\"id\",\"idPlacing\")\n",
    "                .withColumnRenamed(\"cycle\",\"cyclePlacing\")\n",
    "                .withColumnRenamed(\"stressLevel\",\"stressLevelPlacing\")\n",
    "                .withColumnRenamed(\"ts\",\"tsPlacing\")\n",
    "               )\n",
    "\n",
    "join1_sdf = (goodGraspedSafely_sdf.join(\n",
    "    movingWarning_sdf, expr(\"\"\"\n",
    "    (idGrasped == idMoving) AND\n",
    "    (cycleGrasped == cycleMoving)\"\"\" \n",
    "    )))\n",
    "\n",
    "join2_sdf = (join1_sdf.join(\n",
    "  placingSafely_sdf, expr(\"\"\"\n",
    "    (idMoving == idPlacing) AND\n",
    "    (cyclePlacing == cycleMoving )\"\"\" \n",
    "    )))\n",
    "\n",
    "within20sec = join2_sdf.where(\"tsPlacing <= tsGrasped + interval 20 seconds\")\n",
    "\n",
    "e4 = (within20sec\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\")\n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|ID |cycle|\n",
      "+---+-----+\n",
      "|1  |75   |\n",
      "|1  |74   |\n",
      "|1  |73   |\n",
      "|1  |72   |\n",
      "|1  |71   |\n",
      "+---+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT idGrasped AS ID, cyclePlacing AS cycle FROM sinkTable ORDER BY cyclePlacing DESC\").show(5,False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "indeed only the arm whose ID is 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"id\": \"6ba4e4af-2405-4485-b920-169c89c38116\",\n",
      "    \"runId\": \"0aba5bda-450d-4459-9220-d4ec79a27897\",\n",
      "    \"name\": \"sinkTable\",\n",
      "    \"timestamp\": \"2021-10-18T15:31:07.734Z\",\n",
      "    \"batchId\": 49,\n",
      "    \"numInputRows\": 8,\n",
      "    \"inputRowsPerSecond\": 1.0745466756212223,\n",
      "    \"processedRowsPerSecond\": 1.1220196353436185,\n",
      "    \"durationMs\": {\n",
      "        \"addBatch\": 6955,\n",
      "        \"getBatch\": 0,\n",
      "        \"latestOffset\": 0,\n",
      "        \"queryPlanning\": 122,\n",
      "        \"triggerExecution\": 7130,\n",
      "        \"walCommit\": 26\n",
      "    },\n",
      "    \"eventTime\": {\n",
      "        \"watermark\": \"2021-10-18T15:29:39.000Z\"\n",
      "    },\n",
      "    \"stateOperators\": [\n",
      "        {\n",
      "            \"numRowsTotal\": 12,\n",
      "            \"numRowsUpdated\": 0,\n",
      "            \"memoryUsedBytes\": 331072,\n",
      "            \"customMetrics\": {\n",
      "                \"loadedMapCacheHitCount\": 19600,\n",
      "                \"loadedMapCacheMissCount\": 0,\n",
      "                \"stateOnCurrentVersionSizeBytes\": 38400\n",
      "            }\n",
      "        }\n",
      "    ],\n",
      "    \"sources\": [\n",
      "        {\n",
      "            \"description\": \"KafkaV2[Subscribe[RoboticArm]]\",\n",
      "            \"startOffset\": {\n",
      "                \"RoboticArm\": {\n",
      "                    \"0\": 1498\n",
      "                }\n",
      "            },\n",
      "            \"endOffset\": {\n",
      "                \"RoboticArm\": {\n",
      "                    \"0\": 1502\n",
      "                }\n",
      "            },\n",
      "            \"numInputRows\": 8,\n",
      "            \"inputRowsPerSecond\": 1.0745466756212223,\n",
      "            \"processedRowsPerSecond\": 1.1220196353436185\n",
      "        }\n",
      "    ],\n",
      "    \"sink\": {\n",
      "        \"description\": \"MemorySink\",\n",
      "        \"numOutputRows\": 0\n",
      "    }\n",
      "}\n",
      "{'message': 'Stopped', 'isDataAvailable': False, 'isTriggerActive': False}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-83-45ff73b5502d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me3TC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlastProgress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me3TC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import json\n",
    "while True:\n",
    "    print(json.dumps(e3TC.lastProgress, indent=4))\n",
    "    print(e3TC.status)\n",
    "    time.sleep(1)\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "e4.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E5\n",
    "\n",
    "> A continuous query that monitors the results of the previous one (i.e., E4) and counts how many times each robotic arm is present in the stream over a window of 20 seconds updating the counting every 4 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "e5 = (within20sec\n",
    "                     .withWatermark(\"tsPlacing\", \"1 minutes\")\n",
    "                     .groupBy(window(\"tsPlacing\", \"4 minutes\", \"30 seconds\"),\"idGrasped\")\n",
    "                     .count()\n",
    "                     .writeStream\n",
    "                     .format(\"memory\")\n",
    "                     .queryName(\"sinkTable\") \n",
    "                     .start())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------------+---------+-----+\n",
      "|window                                    |idGrasped|count|\n",
      "+------------------------------------------+---------+-----+\n",
      "|[2021-10-18 16:13:00, 2021-10-18 16:17:00]|1        |7    |\n",
      "|[2021-10-18 16:12:30, 2021-10-18 16:16:30]|1        |7    |\n",
      "|[2021-10-18 16:12:00, 2021-10-18 16:16:00]|1        |7    |\n",
      "|[2021-10-18 16:11:30, 2021-10-18 16:15:30]|1        |7    |\n",
      "|[2021-10-18 16:11:00, 2021-10-18 16:15:00]|1        |7    |\n",
      "|[2021-10-18 16:10:30, 2021-10-18 16:14:30]|1        |7    |\n",
      "|[2021-10-18 16:10:00, 2021-10-18 16:14:00]|1        |7    |\n",
      "|[2021-10-18 16:09:30, 2021-10-18 16:13:30]|1        |7    |\n",
      "|[2021-10-18 16:09:00, 2021-10-18 16:13:00]|1        |8    |\n",
      "|[2021-10-18 16:08:30, 2021-10-18 16:12:30]|1        |8    |\n",
      "|[2021-10-18 16:08:00, 2021-10-18 16:12:00]|1        |7    |\n",
      "|[2021-10-18 16:07:30, 2021-10-18 16:11:30]|1        |7    |\n",
      "|[2021-10-18 16:07:00, 2021-10-18 16:11:00]|1        |7    |\n",
      "|[2021-10-18 16:06:30, 2021-10-18 16:10:30]|1        |7    |\n",
      "|[2021-10-18 16:06:00, 2021-10-18 16:10:00]|1        |7    |\n",
      "|[2021-10-18 16:05:30, 2021-10-18 16:09:30]|1        |7    |\n",
      "|[2021-10-18 16:05:00, 2021-10-18 16:09:00]|1        |7    |\n",
      "|[2021-10-18 16:04:30, 2021-10-18 16:08:30]|1        |7    |\n",
      "|[2021-10-18 16:04:00, 2021-10-18 16:08:00]|1        |8    |\n",
      "|[2021-10-18 16:03:30, 2021-10-18 16:07:30]|1        |8    |\n",
      "|[2021-10-18 16:03:00, 2021-10-18 16:07:00]|1        |8    |\n",
      "|[2021-10-18 16:02:30, 2021-10-18 16:06:30]|1        |7    |\n",
      "|[2021-10-18 16:02:00, 2021-10-18 16:06:00]|1        |7    |\n",
      "|[2021-10-18 16:01:30, 2021-10-18 16:05:30]|1        |7    |\n",
      "|[2021-10-18 16:01:00, 2021-10-18 16:05:00]|1        |7    |\n",
      "|[2021-10-18 16:00:30, 2021-10-18 16:04:30]|1        |7    |\n",
      "|[2021-10-18 16:00:00, 2021-10-18 16:04:00]|1        |7    |\n",
      "|[2021-10-18 15:59:30, 2021-10-18 16:03:30]|1        |7    |\n",
      "|[2021-10-18 15:59:00, 2021-10-18 16:03:00]|1        |7    |\n",
      "|[2021-10-18 15:58:30, 2021-10-18 16:02:30]|1        |8    |\n",
      "|[2021-10-18 15:58:00, 2021-10-18 16:02:00]|1        |8    |\n",
      "|[2021-10-18 15:57:30, 2021-10-18 16:01:30]|1        |7    |\n",
      "|[2021-10-18 15:57:00, 2021-10-18 16:01:00]|1        |7    |\n",
      "|[2021-10-18 15:56:30, 2021-10-18 16:00:30]|1        |7    |\n",
      "|[2021-10-18 15:56:00, 2021-10-18 16:00:00]|1        |7    |\n",
      "|[2021-10-18 15:55:30, 2021-10-18 15:59:30]|1        |7    |\n",
      "|[2021-10-18 15:55:00, 2021-10-18 15:59:00]|1        |7    |\n",
      "|[2021-10-18 15:54:30, 2021-10-18 15:58:30]|1        |7    |\n",
      "|[2021-10-18 15:54:00, 2021-10-18 15:58:00]|1        |7    |\n",
      "|[2021-10-18 15:53:30, 2021-10-18 15:57:30]|1        |8    |\n",
      "|[2021-10-18 15:53:00, 2021-10-18 15:57:00]|1        |8    |\n",
      "|[2021-10-18 15:52:30, 2021-10-18 15:56:30]|1        |8    |\n",
      "|[2021-10-18 15:52:00, 2021-10-18 15:56:00]|1        |7    |\n",
      "|[2021-10-18 15:51:30, 2021-10-18 15:55:30]|1        |7    |\n",
      "|[2021-10-18 15:51:00, 2021-10-18 15:55:00]|1        |7    |\n",
      "|[2021-10-18 15:50:30, 2021-10-18 15:54:30]|1        |7    |\n",
      "|[2021-10-18 15:50:00, 2021-10-18 15:54:00]|1        |7    |\n",
      "|[2021-10-18 15:49:30, 2021-10-18 15:53:30]|1        |7    |\n",
      "|[2021-10-18 15:49:00, 2021-10-18 15:53:00]|1        |7    |\n",
      "|[2021-10-18 15:48:30, 2021-10-18 15:52:30]|1        |7    |\n",
      "|[2021-10-18 15:48:00, 2021-10-18 15:52:00]|1        |8    |\n",
      "|[2021-10-18 15:47:30, 2021-10-18 15:51:30]|1        |8    |\n",
      "|[2021-10-18 15:47:00, 2021-10-18 15:51:00]|1        |7    |\n",
      "|[2021-10-18 15:46:30, 2021-10-18 15:50:30]|1        |7    |\n",
      "|[2021-10-18 15:46:00, 2021-10-18 15:50:00]|1        |7    |\n",
      "|[2021-10-18 15:45:30, 2021-10-18 15:49:30]|1        |7    |\n",
      "|[2021-10-18 15:45:00, 2021-10-18 15:49:00]|1        |7    |\n",
      "|[2021-10-18 15:44:30, 2021-10-18 15:48:30]|1        |7    |\n",
      "|[2021-10-18 15:44:00, 2021-10-18 15:48:00]|1        |7    |\n",
      "|[2021-10-18 15:43:30, 2021-10-18 15:47:30]|1        |7    |\n",
      "|[2021-10-18 15:43:00, 2021-10-18 15:47:00]|1        |8    |\n",
      "|[2021-10-18 15:42:30, 2021-10-18 15:46:30]|1        |8    |\n",
      "|[2021-10-18 15:42:00, 2021-10-18 15:46:00]|1        |8    |\n",
      "|[2021-10-18 15:41:30, 2021-10-18 15:45:30]|1        |7    |\n",
      "|[2021-10-18 15:41:00, 2021-10-18 15:45:00]|1        |7    |\n",
      "|[2021-10-18 15:40:30, 2021-10-18 15:44:30]|1        |7    |\n",
      "|[2021-10-18 15:40:00, 2021-10-18 15:44:00]|1        |7    |\n",
      "|[2021-10-18 15:39:30, 2021-10-18 15:43:30]|1        |7    |\n",
      "|[2021-10-18 15:39:00, 2021-10-18 15:43:00]|1        |7    |\n",
      "|[2021-10-18 15:38:30, 2021-10-18 15:42:30]|1        |7    |\n",
      "|[2021-10-18 15:38:00, 2021-10-18 15:42:00]|1        |7    |\n",
      "|[2021-10-18 15:37:30, 2021-10-18 15:41:30]|1        |8    |\n",
      "|[2021-10-18 15:37:00, 2021-10-18 15:41:00]|1        |8    |\n",
      "|[2021-10-18 15:36:30, 2021-10-18 15:40:30]|1        |8    |\n",
      "|[2021-10-18 15:36:00, 2021-10-18 15:40:00]|1        |7    |\n",
      "|[2021-10-18 15:35:30, 2021-10-18 15:39:30]|1        |7    |\n",
      "|[2021-10-18 15:35:00, 2021-10-18 15:39:00]|1        |6    |\n",
      "|[2021-10-18 15:34:30, 2021-10-18 15:38:30]|1        |5    |\n",
      "|[2021-10-18 15:34:00, 2021-10-18 15:38:00]|1        |4    |\n",
      "|[2021-10-18 15:33:30, 2021-10-18 15:37:30]|1        |3    |\n",
      "|[2021-10-18 15:33:00, 2021-10-18 15:37:00]|1        |2    |\n",
      "|[2021-10-18 15:32:30, 2021-10-18 15:36:30]|1        |1    |\n",
      "|[2021-10-18 15:32:00, 2021-10-18 15:36:00]|1        |1    |\n",
      "+------------------------------------------+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM sinkTable ORDER BY window DESC\").show(100,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "e5.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
